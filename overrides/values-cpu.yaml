# llm-service:
#   device: cpu
#   models:
#     llama-guard-3-1b:
#       enabled: true

global:
  models:
    llama-3-2-1b-instruct:
      id: meta-llama/Llama-3.2-1B-Instruct
      enabled: true
